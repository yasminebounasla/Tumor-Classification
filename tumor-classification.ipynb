{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0   1         M       11.840         18.70           77.93      440.6   \n",
      "1   2         B       12.760         18.84           81.87      496.6   \n",
      "2   3         M       23.290         26.67          158.90     1685.0   \n",
      "3   4         B       12.560         19.07           81.92      485.8   \n",
      "4   5         B        9.742         15.67           61.50      289.9   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11090           0.15160         0.12180              0.05182   \n",
      "1          0.09676           0.07952         0.02688              0.01781   \n",
      "2          0.11410           0.20840         0.35230              0.16200   \n",
      "3          0.08760           0.10380         0.10300              0.04391   \n",
      "4          0.09037           0.04689         0.01103              0.01407   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         16.82          28.12           119.40       888.7   \n",
      "1  ...         13.75          25.99            87.82       579.7   \n",
      "2  ...         25.12          32.68           177.00      1986.0   \n",
      "3  ...         13.37          22.43            89.02       547.4   \n",
      "4  ...         10.75          20.88            68.09       355.2   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1637             0.5775          0.69560               0.15460   \n",
      "1            0.1298             0.1839          0.12550               0.08312   \n",
      "2            0.1536             0.4167          0.78920               0.27330   \n",
      "3            0.1096             0.2002          0.23880               0.09265   \n",
      "4            0.1467             0.0937          0.04043               0.05159   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4761                  0.14020  \n",
      "1          0.2744                  0.07238  \n",
      "2          0.3198                  0.08762  \n",
      "3          0.2121                  0.07188  \n",
      "4          0.2841                  0.08175  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train_data.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       400 non-null    int64  \n",
      " 1   diagnosis                400 non-null    object \n",
      " 2   radius_mean              400 non-null    float64\n",
      " 3   texture_mean             400 non-null    float64\n",
      " 4   perimeter_mean           400 non-null    float64\n",
      " 5   area_mean                400 non-null    float64\n",
      " 6   smoothness_mean          400 non-null    float64\n",
      " 7   compactness_mean         400 non-null    float64\n",
      " 8   concavity_mean           400 non-null    float64\n",
      " 9   concave points_mean      400 non-null    float64\n",
      " 10  symmetry_mean            400 non-null    float64\n",
      " 11  fractal_dimension_mean   400 non-null    float64\n",
      " 12  radius_se                400 non-null    float64\n",
      " 13  texture_se               400 non-null    float64\n",
      " 14  perimeter_se             400 non-null    float64\n",
      " 15  area_se                  400 non-null    float64\n",
      " 16  smoothness_se            400 non-null    float64\n",
      " 17  compactness_se           400 non-null    float64\n",
      " 18  concavity_se             400 non-null    float64\n",
      " 19  concave points_se        400 non-null    float64\n",
      " 20  symmetry_se              400 non-null    float64\n",
      " 21  fractal_dimension_se     400 non-null    float64\n",
      " 22  radius_worst             400 non-null    float64\n",
      " 23  texture_worst            400 non-null    float64\n",
      " 24  perimeter_worst          400 non-null    float64\n",
      " 25  area_worst               400 non-null    float64\n",
      " 26  smoothness_worst         400 non-null    float64\n",
      " 27  compactness_worst        400 non-null    float64\n",
      " 28  concavity_worst          400 non-null    float64\n",
      " 29  concave points_worst     400 non-null    float64\n",
      " 30  symmetry_worst           400 non-null    float64\n",
      " 31  fractal_dimension_worst  400 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 100.1+ KB\n",
      "None\n",
      "               id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  400.000000   400.000000    400.000000      400.000000   400.000000   \n",
      "mean   200.500000    14.178867     19.337325       92.338625   658.442250   \n",
      "std    115.614301     3.519271      4.263096       24.283199   346.971049   \n",
      "min      1.000000     7.691000     10.910000       47.920000   170.400000   \n",
      "25%    100.750000    11.710000     16.327500       75.267500   420.875000   \n",
      "50%    200.500000    13.375000     18.830000       86.415000   552.600000   \n",
      "75%    300.250000    16.180000     21.547500      107.100000   810.600000   \n",
      "max    400.000000    28.110000     39.280000      188.500000  2499.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       400.000000        400.000000      400.000000           400.000000   \n",
      "mean          0.096201          0.105724        0.091194             0.049577   \n",
      "std           0.014259          0.054261        0.082886             0.039690   \n",
      "min           0.052630          0.023440        0.000000             0.000000   \n",
      "25%           0.085828          0.065675        0.029575             0.020310   \n",
      "50%           0.095890          0.095275        0.061680             0.033300   \n",
      "75%           0.105525          0.130700        0.133825             0.077677   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "count     400.000000  ...    400.000000     400.000000       400.000000   \n",
      "mean        0.181336  ...     16.313273      25.664100       107.450900   \n",
      "std         0.028094  ...      4.797903       6.157422        33.144074   \n",
      "min         0.116700  ...      8.678000      12.490000        54.490000   \n",
      "25%         0.161975  ...     13.010000      21.367500        84.080000   \n",
      "50%         0.179150  ...     14.995000      25.305000        97.660000   \n",
      "75%         0.195450  ...     19.192500      29.105000       127.000000   \n",
      "max         0.304000  ...     33.130000      49.540000       229.300000   \n",
      "\n",
      "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count   400.000000        400.000000         400.000000       400.000000   \n",
      "mean    881.983750          0.131948           0.257732         0.276656   \n",
      "std     551.457403          0.022377           0.158797         0.216579   \n",
      "min     223.600000          0.071170           0.027290         0.000000   \n",
      "25%     513.700000          0.116600           0.148500         0.118475   \n",
      "50%     688.750000          0.131000           0.217000         0.223050   \n",
      "75%    1114.000000          0.145125           0.341600         0.385500   \n",
      "max    3432.000000          0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "count            400.000000      400.000000               400.000000  \n",
      "mean               0.115127        0.290352                 0.084204  \n",
      "std                0.066060        0.062723                 0.018338  \n",
      "min                0.000000        0.160300                 0.055250  \n",
      "25%                0.064768        0.250000                 0.071962  \n",
      "50%                0.100015        0.279800                 0.080065  \n",
      "75%                0.165525        0.318025                 0.091415  \n",
      "max                0.291000        0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "id                         0\n",
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.info())  # Overview of columns and types\n",
    "print(data.describe())  # Statistical summary\n",
    "print(data.isnull().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0         M       11.840         18.70           77.93      440.6   \n",
      "1         B       12.760         18.84           81.87      496.6   \n",
      "2         M       23.290         26.67          158.90     1685.0   \n",
      "3         B       12.560         19.07           81.92      485.8   \n",
      "4         B        9.742         15.67           61.50      289.9   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11090           0.15160         0.12180              0.05182   \n",
      "1          0.09676           0.07952         0.02688              0.01781   \n",
      "2          0.11410           0.20840         0.35230              0.16200   \n",
      "3          0.08760           0.10380         0.10300              0.04391   \n",
      "4          0.09037           0.04689         0.01103              0.01407   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2301  ...         16.82          28.12           119.40   \n",
      "1         0.1759  ...         13.75          25.99            87.82   \n",
      "2         0.2200  ...         25.12          32.68           177.00   \n",
      "3         0.1533  ...         13.37          22.43            89.02   \n",
      "4         0.2081  ...         10.75          20.88            68.09   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0       888.7            0.1637             0.5775          0.69560   \n",
      "1       579.7            0.1298             0.1839          0.12550   \n",
      "2      1986.0            0.1536             0.4167          0.78920   \n",
      "3       547.4            0.1096             0.2002          0.23880   \n",
      "4       355.2            0.1467             0.0937          0.04043   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0               0.15460          0.4761                  0.14020  \n",
      "1               0.08312          0.2744                  0.07238  \n",
      "2               0.27330          0.3198                  0.08762  \n",
      "3               0.09265          0.2121                  0.07188  \n",
      "4               0.05159          0.2841                  0.08175  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data spliting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split the data\n",
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.64502305 -0.15511094 -0.61801263 ... -0.55175756 -1.35835563\n",
      "  -0.71509895]\n",
      " [-0.45372907 -1.40337625 -0.46863784 ... -0.5654998  -0.33626973\n",
      "  -0.64192628]\n",
      " [ 0.78702492  0.06421044  0.62793521 ... -0.16563061  3.23022841\n",
      "  -1.31212141]\n",
      " ...\n",
      " [ 0.3482114   0.42127804  0.38265885 ... -0.08858885 -0.23486265\n",
      "  -0.12446054]\n",
      " [ 1.13692956 -0.23876394  1.13459247 ...  0.60201517 -0.53259929\n",
      "  -0.95752739]\n",
      " [ 0.08402194 -1.11033384  0.16542197 ...  1.58540814  2.48134235\n",
      "   0.69177894]]\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Trainning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_resampled_scaled, y_resampled)\n",
    "svm_y_pred = svm_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "\n",
    "# Convert to percentage\n",
    "svm_accuracy_percentage = svm_accuracy * 100\n",
    "\n",
    "print(f'SVM Accuracy: {svm_accuracy_percentage:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.98      0.99        59\n",
      "      benign       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.98        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, svm_y_pred, target_names=['malignant', 'benign']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 98.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(svm_model, X_resampled_scaled, y_resampled, cv=5)\n",
    "print(f'Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted diagnosis is: benign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bounasla Yasmine\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def predict_diagnosis(features):\n",
    "    # Convert the features list to a numpy array and reshape it\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    \n",
    "    # Scale the input features using the same scaler you used for training\n",
    "    scaled_features = scaler.transform(features_array)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = svm_model.predict(scaled_features) \n",
    "\n",
    "    if prediction[0] == 'M':\n",
    "        return 'malignant'\n",
    "    else:\n",
    "        return 'benign'\n",
    "    \n",
    "\n",
    "input_features = [12.76,18.84,81.87,496.6,0.09676,0.07952,0.02688,0.01781,0.1759,0.06183,0.2213,1.285,1.535,17.26,0.005608,0.01646,0.01529,0.009997,0.01909,0.002133,13.75,25.99,87.82,579.7,0.1298,0.1839,0.1255,0.08312,0.2744,0.07238]\n",
    "\n",
    "# Get the prediction\n",
    "result = predict_diagnosis(input_features)\n",
    "print(f'The predicted diagnosis is: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted diagnosis is: malignant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bounasla Yasmine\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "def predict_diagnosis(features):\n",
    "    # Convert the features list to a numpy array and reshape it\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    \n",
    "    # Scale the input features using the same scaler you used for training\n",
    "    scaled_features = scaler.transform(features_array)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = svm_model.predict(scaled_features) \n",
    "\n",
    "    if prediction[0] == 'M':\n",
    "        return 'malignant'\n",
    "    else:\n",
    "        return 'benign'\n",
    "    \n",
    "\n",
    "input_features = [13.82,24.49,92.33,595.9,0.1162,0.1681,0.1357,0.06759,0.2275,0.07237,0.4751,1.528,2.974,39.05,0.00968,0.03856,0.03476,0.01616,0.02434,0.006995,16.01,32.94,106.0,788.0,0.1794,0.3966,0.3381,0.1521,0.3651,0.1183]\n",
    "\n",
    "# Get the prediction\n",
    "result = predict_diagnosis(input_features)\n",
    "print(f'The predicted diagnosis is: {result}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
